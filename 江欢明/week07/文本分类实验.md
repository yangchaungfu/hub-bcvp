# 文本分类模型超参数实验结果对比表

## 实验结果汇总

### 1. **Gated CNN模型**（门控卷积神经网络）

| 学习率 | 批次大小 | 池化方式 | 准确率 | 性能评级 |
|--------|----------|----------|--------|----------|
| 0.001  | 64       | avg      | 64.72% | ★★★★☆ |
| 0.001  | 64       | max      | 66.11% | ★★★★★ |
| 0.001  | 128      | avg      | 60.83% | ★★★☆☆ |
| 0.001  | 128      | max      | 64.17% | ★★★★☆ |
| 0.0001 | 64       | avg      | 33.06% | ★☆☆☆☆ |
| 0.0001 | 64       | max      | 38.89% | ★★☆☆☆ |
| 0.0001 | 128      | avg      | 26.39% | ★☆☆☆☆ |
| 0.0001 | 128      | max      | 26.94% | ★☆☆☆☆ |

### 2. **BERT模型**（预训练语言模型）

| 学习率 | 批次大小 | 池化方式 | 准确率 | 性能评级 |
|--------|----------|----------|--------|----------|
| 0.001  | 64       | avg      | 5.00%  | ★☆☆☆☆ |
| 0.001  | 64       | max      | 5.00%  | ★☆☆☆☆ |
| 0.001  | 128      | avg      | 3.61%  | ★☆☆☆☆ |
| 0.001  | 128      | max      | 5.00%  | ★☆☆☆☆ |
| 0.0001 | 64       | avg      | 85.56% | ★★★★★★ |
| 0.0001 | 64       | max      | 80.83% | ★★★★★☆ |
| 0.0001 | 128      | avg      | 86.39% | ★★★★★★ |
| 0.0001 | 128      | max      | 86.11% | ★★★★★★ |

### 3. **LSTM模型**（长短期记忆网络）

| 学习率 | 批次大小 | 池化方式 | 准确率 | 性能评级 |
|--------|----------|----------|--------|----------|
| 0.001  | 64       | avg      | 55.56% | ★★★☆☆ |
| 0.001  | 64       | max      | 55.00% | ★★★☆☆ |
| 0.001  | 128      | avg      | 53.61% | ★★★☆☆ |
| 0.001  | 128      | max      | 55.83% | ★★★☆☆ |
| 0.0001 | 64       | avg      | 15.83% | ★☆☆☆☆ |
| 0.0001 | 64       | max      | 20.83% | ★☆☆☆☆ |
| 0.0001 | 128      | avg      | 20.28% | ★☆☆☆☆ |
| 0.0001 | 128      | max      | 15.00% | ★☆☆☆☆ |

---

## 关键发现分析

### **模型性能总体排名**

| 排名 | 模型 | 最佳准确率 | 最佳配置 |
|------|------|------------|----------|
| 1 | **BERT** | **86.39%** | 学习率=0.0001，批次=128，池化=avg |
| 2 | Gated CNN | 66.11% | 学习率=0.001，批次=64，池化=max |
| 3 | LSTM | 55.83% | 学习率=0.001，批次=128，池化=max |

### **学习率敏感性分析**

| 模型 | 学习率0.001效果 | 学习率0.0001效果 | 最优学习率 |
|------|-----------------|------------------|------------|
| **BERT** | 极差(3-5%) | 优秀(80-86%) | **0.0001** |
| Gated CNN | 良好(60-66%) | 差(26-39%) | **0.001** |
| LSTM | 中等(53-56%) | 差(15-21%) | **0.001** |

### **批次大小影响**

| 模型 | 批次64效果 | 批次128效果 | 最佳批次 |
|------|------------|-------------|----------|
| BERT | 85.56%-80.83% | 86.39%-86.11% | **128** |
| Gated CNN | 64.72%-66.11% | 60.83%-64.17% | **64** |
| LSTM | 55.56%-55.00% | 53.61%-55.83% | 差异不大 |

### **池化方式对比**

| 模型 | avg池化效果 | max池化效果 | 最佳池化 |
|------|-------------|-------------|----------|
| BERT | 85.56%-86.39% | 80.83%-86.11% | **avg**（稍优） |
| Gated CNN | 64.72%-60.83% | 66.11%-64.17% | **max**（稍优） |
| LSTM | 55.56%-53.61% | 55.00%-55.83% | 差异不大 |

---

## 性能评级标准

- ★★★★★★：85%以上（优秀）
- ★★★★★：80-85%（很好）
- ★★★★☆：65-80%（良好）
- ★★★☆☆：50-65%（中等）
- ★★☆☆☆：35-50%（较差）
- ★☆☆☆☆：35%以下（差）

---

## 详细分析报告

### **BERT模型的惊人表现**
1. **对学习率极度敏感**：BERT在0.001学习率下几乎不学习（5%准确率），但在0.0001学习率下达到**85%以上**的顶级性能
2. **批次大小影响小**：在合适学习率下，批次64和128都表现优秀
3. **轻微池化偏好**：平均池化略优于最大池化

### **Gated CNN模型的稳健性**
1. **中等但稳定**：在0.001学习率下能达到65%左右的稳定性能
2. **批次敏感**：小批次（64）表现明显优于大批次（128）
3. **学习率敏感**：0.0001学习率下性能急剧下降

### **LSTM模型的平庸表现**
1. **最佳性能有限**：最高仅55.83%，远低于其他模型
2. **学习率影响大**：0.0001学习率下表现很差
3. **池化差异小**：不同池化方式对结果影响不大

---

## 配置推荐

### **BERT模型最佳实践**
```
学习率: 0.0001 (或更小如5e-5)
批次大小: 64-128 均可
池化方式: avg
训练周期: 可能需要更多epoch
```

### **Gated CNN最佳实践**
```
学习率: 0.001
批次大小: 64
池化方式: max
适合: 计算资源有限时，仍能达到不错效果
```

### **应避免的配置**
1. BERT + 0.001学习率（完全无效）
2. Gated CNN + 0.0001学习率（性能极差）
3. LSTM + 0.0001学习率（无法有效学习）

---

## 进一步优化建议

1. **BERT模型**：
   - 尝试更小的学习率（如2e-5）
   - 增加训练epoch数
   - 尝试不同的优化器（AdamW）

2. **Gated CNN**：
   - 尝试中间学习率（如0.0005）
   - 调整卷积核大小和层数
   - 增加dropout防止过拟合

3. **LSTM**：
   - 尝试双向LSTM
   - 增加层数或隐藏单元数
   - 使用预训练词向量

---

**结论**：BERT在适当配置下表现最优，但需要极低的学习率；Gated CNN在中等配置下表现稳定；LSTM在此任务中表现相对较差。
